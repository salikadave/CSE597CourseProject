{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Getting Started: COGMEN\n",
        "\n",
        "Paper Link: https://arxiv.org/pdf/2205.02455v1.pdf"
      ],
      "metadata": {
        "id": "fcIiz6sqqLKe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTHDQNtWA6AL",
        "outputId": "0ea0ad5f-722d-4ce4-80fe-b24ae33ade9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'COGMEN'...\n",
            "remote: Enumerating objects: 58, done.\u001b[K\n",
            "remote: Total 58 (delta 0), reused 0 (delta 0), pack-reused 58\u001b[K\n",
            "Receiving objects: 100% (58/58), 153.23 MiB | 36.41 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n",
            "Updating files: 100% (26/26), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Exploration-Lab/COGMEN.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd COGMEN/\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uL-s77SBJvY",
        "outputId": "4cb72201-f8d3-4073-cca8-0d4925d127fd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/COGMEN\n",
            "cogmen\t\t\t data\t  LICENSE\t     models\t    README.md\t train.py\n",
            "COGMEN_architecture.png  eval.py  model_checkpoints  preprocess.py  run_eval.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Requirements"
      ],
      "metadata": {
        "id": "rsWXLhRfrOoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "\n",
        "%pip install comet_ml --upgrade --quiet\n",
        "\n",
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMyKt-4pBOhB",
        "outputId": "c00aa36b-031a-4cab-df49-c2cddec6958d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.7/586.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.7/514.7 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.16.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence-transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=e21320c7eeeec37553b9cd69e2dad1605b3fc9e1a899f95f4fb395ff011f590a\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: sentencepiece, sentence-transformers\n",
            "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cpu.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4wfk1vxDSvv",
        "outputId": "8e0e11b8-66b8-4a5d-fd52-bab8deb92dea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.1.0+cpu.html\n",
            "Collecting pyg_lib\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/pyg_lib-0.3.1%2Bpt21cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_scatter-2.1.2%2Bpt21cpu-cp310-cp310-linux_x86_64.whl (497 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.3/497.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_sparse-0.6.18%2Bpt21cpu-cp310-cp310-linux_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_cluster-1.6.3%2Bpt21cpu-cp310-cp310-linux_x86_64.whl (745 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m745.7/745.7 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch_spline_conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.1.0%2Bcpu/torch_spline_conv-1.2.2%2Bpt21cpu-cp310-cp310-linux_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.5/208.5 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch_sparse) (1.23.5)\n",
            "Installing collected packages: torch_spline_conv, torch_scatter, pyg_lib, torch_sparse, torch_cluster\n",
            "Successfully installed pyg_lib-0.3.1+pt21cpu torch_cluster-1.6.3+pt21cpu torch_scatter-2.1.2+pt21cpu torch_sparse-0.6.18+pt21cpu torch_spline_conv-1.2.2+pt21cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "gdAgGHTgrT5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python preprocess.py --dataset=\"iemocap_4\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-2u-EALBq96",
        "outputId": "6d13246a-15d0-458b-d32b-630c3a123cff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".gitattributes: 100% 391/391 [00:00<00:00, 2.15MB/s]\n",
            "1_Pooling/config.json: 100% 190/190 [00:00<00:00, 1.37MB/s]\n",
            "README.md: 100% 3.74k/3.74k [00:00<00:00, 22.0MB/s]\n",
            "config.json: 100% 718/718 [00:00<00:00, 3.71MB/s]\n",
            "config_sentence_transformers.json: 100% 122/122 [00:00<00:00, 823kB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 3.48MB/s]\n",
            "pytorch_model.bin: 100% 329M/329M [00:02<00:00, 129MB/s]\n",
            "sentence_bert_config.json: 100% 53.0/53.0 [00:00<00:00, 242kB/s]\n",
            "special_tokens_map.json: 100% 239/239 [00:00<00:00, 1.15MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 4.15MB/s]\n",
            "tokenizer_config.json: 100% 1.35k/1.35k [00:00<00:00, 7.04MB/s]\n",
            "vocab.json: 100% 798k/798k [00:00<00:00, 11.5MB/s]\n",
            "modules.json: 100% 229/229 [00:00<00:00, 1.01MB/s]\n",
            "Seed set\n",
            "train: 100% 108/108 [00:12<00:00,  8.93it/s]\n",
            "dev: 100% 12/12 [00:00<00:00, 25.16it/s]\n",
            "test: 100% 31/31 [00:01<00:00, 25.74it/s]\n",
            "12/12/2023 06:25:52 train vids:\n",
            "12/12/2023 06:25:52 ['Ses01F_impro01', 'Ses01F_impro02', 'Ses01F_impro04', 'Ses01F_impro05', 'Ses01F_impro06', 'Ses01F_impro07', 'Ses01F_script01_1', 'Ses01F_script01_2', 'Ses01F_script01_3', 'Ses01F_script02_1', 'Ses01F_script03_1', 'Ses01F_script03_2', 'Ses01M_impro01', 'Ses01M_impro02', 'Ses01M_impro03', 'Ses01M_impro04', 'Ses01M_impro06', 'Ses01M_impro07', 'Ses01M_script01_1', 'Ses01M_script01_2', 'Ses01M_script01_3', 'Ses01M_script02_1', 'Ses01M_script02_2', 'Ses01M_script03_1', 'Ses01M_script03_2', 'Ses02F_impro01', 'Ses02F_impro02', 'Ses02F_impro03', 'Ses02F_impro04', 'Ses02F_impro06', 'Ses02F_impro07', 'Ses02F_impro08', 'Ses02F_script01_2', 'Ses02F_script02_1', 'Ses02F_script02_2', 'Ses02F_script03_1', 'Ses02F_script03_2', 'Ses02M_impro01', 'Ses02M_impro02', 'Ses02M_impro03', 'Ses02M_impro04', 'Ses02M_impro05', 'Ses02M_impro06', 'Ses02M_impro07', 'Ses02M_impro08', 'Ses02M_script01_1', 'Ses02M_script01_2', 'Ses02M_script01_3', 'Ses02M_script02_1', 'Ses02M_script03_1', 'Ses02M_script03_2', 'Ses03F_impro01', 'Ses03F_impro02', 'Ses03F_impro03', 'Ses03F_impro04', 'Ses03F_impro05', 'Ses03F_impro06', 'Ses03F_impro07', 'Ses03F_impro08', 'Ses03F_script01_1', 'Ses03F_script01_2', 'Ses03F_script01_3', 'Ses03F_script02_1', 'Ses03F_script02_2', 'Ses03F_script03_2', 'Ses03M_impro01', 'Ses03M_impro02', 'Ses03M_impro03', 'Ses03M_impro04', 'Ses03M_impro05a', 'Ses03M_impro06', 'Ses03M_impro07', 'Ses03M_impro08a', 'Ses03M_script01_1', 'Ses03M_script01_2', 'Ses03M_script01_3', 'Ses03M_script02_1', 'Ses03M_script02_2', 'Ses03M_script03_1', 'Ses03M_script03_2', 'Ses04F_impro01', 'Ses04F_impro02', 'Ses04F_impro03', 'Ses04F_impro04', 'Ses04F_impro05', 'Ses04F_impro06', 'Ses04F_impro08', 'Ses04F_script01_1', 'Ses04F_script01_2', 'Ses04F_script01_3', 'Ses04F_script02_1', 'Ses04F_script02_2', 'Ses04F_script03_1', 'Ses04F_script03_2', 'Ses04M_impro01', 'Ses04M_impro02', 'Ses04M_impro03', 'Ses04M_impro05', 'Ses04M_impro06', 'Ses04M_impro07', 'Ses04M_impro08', 'Ses04M_script01_1', 'Ses04M_script01_2', 'Ses04M_script01_3', 'Ses04M_script02_1', 'Ses04M_script02_2', 'Ses04M_script03_1', 'Ses04M_script03_2']\n",
            "12/12/2023 06:25:52 dev vids:\n",
            "12/12/2023 06:25:52 ['Ses01F_impro03', 'Ses01F_script02_2', 'Ses01M_impro05', 'Ses02F_impro05', 'Ses02F_script01_1', 'Ses02F_script01_3', 'Ses02M_script02_2', 'Ses03F_script03_1', 'Ses03M_impro05b', 'Ses03M_impro08b', 'Ses04F_impro07', 'Ses04M_impro04']\n",
            "12/12/2023 06:25:52 test vids:\n",
            "12/12/2023 06:25:52 ['Ses05F_impro01', 'Ses05F_impro02', 'Ses05F_impro03', 'Ses05F_impro04', 'Ses05F_impro05', 'Ses05F_impro06', 'Ses05F_impro07', 'Ses05F_impro08', 'Ses05F_script01_1', 'Ses05F_script01_2', 'Ses05F_script01_3', 'Ses05F_script02_1', 'Ses05F_script02_2', 'Ses05F_script03_1', 'Ses05F_script03_2', 'Ses05M_impro01', 'Ses05M_impro02', 'Ses05M_impro03', 'Ses05M_impro04', 'Ses05M_impro05', 'Ses05M_impro06', 'Ses05M_impro07', 'Ses05M_impro08', 'Ses05M_script01_1', 'Ses05M_script01_1b', 'Ses05M_script01_2', 'Ses05M_script01_3', 'Ses05M_script02_1', 'Ses05M_script02_2', 'Ses05M_script03_1', 'Ses05M_script03_2']\n",
            "12/12/2023 06:25:52 number of train samples: 108\n",
            "12/12/2023 06:25:52 number of dev samples: 12\n",
            "12/12/2023 06:25:52 number of test samples: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "\n",
        "Epochs: 55\n",
        "\n",
        "Modalities: A+T+V -> (Audio + Textual + Visual)"
      ],
      "metadata": {
        "id": "zSuJjV7hqeYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset=\"iemocap_4\" --modalities=\"atv\" --from_begin --epochs=55"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaCWLY0QDDZc",
        "outputId": "356d5b1a-d455-4205-f3ca-cde9d1e47631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set\n",
            "12/10/2023 12:09:26 Loaded data.\n",
            "SeqContext-> USING Transformer\n",
            "args.drop_rate: 0.5\n",
            "Using Scheduler\n",
            "12/10/2023 12:09:26 Start training...\n",
            "train epoch 1: 100% 4/4 [00:15<00:00,  3.99s/it]\n",
            "12/10/2023 12:09:42 \n",
            "12/10/2023 12:09:42 [Epoch 1] [Loss: 5.505564] [Time: 15.978304]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.05s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.03s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.0000    0.0000    0.0000       144\n",
            "         sad     0.3775    0.8367    0.5203       245\n",
            "         neu     0.4948    0.2500    0.3322       384\n",
            "         ang     0.6068    0.7353    0.6649       170\n",
            "\n",
            "    accuracy                         0.4517       943\n",
            "   macro avg     0.3698    0.4555    0.3793       943\n",
            "weighted avg     0.4090    0.4517    0.3903       943\n",
            "\n",
            "12/10/2023 12:09:46 [Dev set] [f1 0.3997]\n",
            "12/10/2023 12:09:46 Save the best model.\n",
            "12/10/2023 12:09:46 [Test set] [f1 0.3903]\n",
            "train epoch 2: 100% 4/4 [00:16<00:00,  4.05s/it]\n",
            "12/10/2023 12:10:02 \n",
            "12/10/2023 12:10:02 [Epoch 2] [Loss: 5.063665] [Time: 16.218894]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.03it/s]\n",
            "test: 100% 1/1 [00:02<00:00,  2.90s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.0000    0.0000    0.0000       144\n",
            "         sad     0.5984    0.8939    0.7169       245\n",
            "         neu     0.6639    0.6276    0.6452       384\n",
            "         ang     0.6588    0.8176    0.7297       170\n",
            "\n",
            "    accuracy                         0.6352       943\n",
            "   macro avg     0.4803    0.5848    0.5229       943\n",
            "weighted avg     0.5446    0.6352    0.5805       943\n",
            "\n",
            "12/10/2023 12:10:06 [Dev set] [f1 0.4885]\n",
            "12/10/2023 12:10:06 Save the best model.\n",
            "12/10/2023 12:10:06 [Test set] [f1 0.5805]\n",
            "train epoch 3: 100% 4/4 [00:15<00:00,  3.89s/it]\n",
            "12/10/2023 12:10:22 \n",
            "12/10/2023 12:10:22 [Epoch 3] [Loss: 4.724163] [Time: 15.548352]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.05s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.41s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7391    0.2361    0.3579       144\n",
            "         sad     0.6531    0.9143    0.7619       245\n",
            "         neu     0.7337    0.6458    0.6870       384\n",
            "         ang     0.6620    0.8412    0.7409       170\n",
            "\n",
            "    accuracy                         0.6882       943\n",
            "   macro avg     0.6970    0.6594    0.6369       943\n",
            "weighted avg     0.7007    0.6882    0.6659       943\n",
            "\n",
            "12/10/2023 12:10:26 [Dev set] [f1 0.6003]\n",
            "12/10/2023 12:10:26 Save the best model.\n",
            "12/10/2023 12:10:26 [Test set] [f1 0.6659]\n",
            "train epoch 4: 100% 4/4 [00:15<00:00,  3.83s/it]\n",
            "12/10/2023 12:10:42 \n",
            "12/10/2023 12:10:42 [Epoch 4] [Loss: 4.502255] [Time: 15.328972]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.92s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8615    0.3889    0.5359       144\n",
            "         sad     0.6260    0.9429    0.7524       245\n",
            "         neu     0.8263    0.5573    0.6656       384\n",
            "         ang     0.6120    0.9000    0.7286       170\n",
            "\n",
            "    accuracy                         0.6935       943\n",
            "   macro avg     0.7315    0.6973    0.6706       943\n",
            "weighted avg     0.7410    0.6935    0.6797       943\n",
            "\n",
            "12/10/2023 12:10:46 [Dev set] [f1 0.6031]\n",
            "12/10/2023 12:10:46 Save the best model.\n",
            "12/10/2023 12:10:46 [Test set] [f1 0.6797]\n",
            "train epoch 5: 100% 4/4 [00:15<00:00,  3.92s/it]\n",
            "12/10/2023 12:11:02 \n",
            "12/10/2023 12:11:02 [Epoch 5] [Loss: 4.314538] [Time: 15.694752]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.30s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.16s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8676    0.4097    0.5566       144\n",
            "         sad     0.6758    0.9020    0.7727       245\n",
            "         neu     0.8233    0.6432    0.7222       384\n",
            "         ang     0.6169    0.9000    0.7321       170\n",
            "\n",
            "    accuracy                         0.7211       943\n",
            "   macro avg     0.7459    0.7137    0.6959       943\n",
            "weighted avg     0.7546    0.7211    0.7118       943\n",
            "\n",
            "12/10/2023 12:11:06 [Dev set] [f1 0.6103]\n",
            "12/10/2023 12:11:06 Save the best model.\n",
            "12/10/2023 12:11:06 [Test set] [f1 0.7118]\n",
            "train epoch 6: 100% 4/4 [00:15<00:00,  3.83s/it]\n",
            "12/10/2023 12:11:22 \n",
            "12/10/2023 12:11:22 [Epoch 6] [Loss: 4.255981] [Time: 15.321924]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.01it/s]\n",
            "test: 100% 1/1 [00:02<00:00,  2.95s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8690    0.5069    0.6404       144\n",
            "         sad     0.7010    0.8612    0.7729       245\n",
            "         neu     0.8469    0.7057    0.7699       384\n",
            "         ang     0.6303    0.8824    0.7353       170\n",
            "\n",
            "    accuracy                         0.7476       943\n",
            "   macro avg     0.7618    0.7391    0.7296       943\n",
            "weighted avg     0.7733    0.7476    0.7447       943\n",
            "\n",
            "12/10/2023 12:11:25 [Dev set] [f1 0.6705]\n",
            "12/10/2023 12:11:26 Save the best model.\n",
            "12/10/2023 12:11:26 [Test set] [f1 0.7447]\n",
            "train epoch 7: 100% 4/4 [00:15<00:00,  3.90s/it]\n",
            "12/10/2023 12:11:41 \n",
            "12/10/2023 12:11:41 [Epoch 7] [Loss: 4.092727] [Time: 15.611116]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.01it/s]\n",
            "test: 100% 1/1 [00:02<00:00,  2.90s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8072    0.4653    0.5903       144\n",
            "         sad     0.6667    0.8571    0.7500       245\n",
            "         neu     0.8354    0.6875    0.7543       384\n",
            "         ang     0.6507    0.8765    0.7469       170\n",
            "\n",
            "    accuracy                         0.7317       943\n",
            "   macro avg     0.7400    0.7216    0.7104       943\n",
            "weighted avg     0.7540    0.7317    0.7268       943\n",
            "\n",
            "12/10/2023 12:11:45 [Dev set] [f1 0.6735]\n",
            "12/10/2023 12:11:45 Save the best model.\n",
            "12/10/2023 12:11:45 [Test set] [f1 0.7268]\n",
            "train epoch 8: 100% 4/4 [00:15<00:00,  3.89s/it]\n",
            "12/10/2023 12:12:01 \n",
            "12/10/2023 12:12:01 [Epoch 8] [Loss: 3.918284] [Time: 15.567079]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.02s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.35s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8667    0.5417    0.6667       144\n",
            "         sad     0.6980    0.8490    0.7661       245\n",
            "         neu     0.8390    0.7057    0.7666       384\n",
            "         ang     0.6509    0.8882    0.7512       170\n",
            "\n",
            "    accuracy                         0.7508       943\n",
            "   macro avg     0.7636    0.7462    0.7377       943\n",
            "weighted avg     0.7727    0.7508    0.7485       943\n",
            "\n",
            "12/10/2023 12:12:05 [Dev set] [f1 0.6845]\n",
            "12/10/2023 12:12:05 Save the best model.\n",
            "12/10/2023 12:12:05 [Test set] [f1 0.7485]\n",
            "train epoch 9: 100% 4/4 [00:15<00:00,  3.96s/it]\n",
            "12/10/2023 12:12:21 \n",
            "12/10/2023 12:12:21 [Epoch 9] [Loss: 3.940365] [Time: 15.831016]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.90s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8478    0.5417    0.6610       144\n",
            "         sad     0.6990    0.8816    0.7798       245\n",
            "         neu     0.8349    0.7109    0.7679       384\n",
            "         ang     0.6837    0.8647    0.7636       170\n",
            "\n",
            "    accuracy                         0.7572       943\n",
            "   macro avg     0.7664    0.7497    0.7431       943\n",
            "weighted avg     0.7743    0.7572    0.7539       943\n",
            "\n",
            "12/10/2023 12:12:25 [Dev set] [f1 0.6963]\n",
            "12/10/2023 12:12:25 Save the best model.\n",
            "12/10/2023 12:12:25 [Test set] [f1 0.7539]\n",
            "train epoch 10: 100% 4/4 [00:16<00:00,  4.02s/it]\n",
            "12/10/2023 12:12:41 \n",
            "12/10/2023 12:12:41 [Epoch 10] [Loss: 3.623504] [Time: 16.066195]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.29s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.02s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8791    0.5556    0.6809       144\n",
            "         sad     0.6975    0.9224    0.7944       245\n",
            "         neu     0.8558    0.7266    0.7859       384\n",
            "         ang     0.7079    0.8412    0.7688       170\n",
            "\n",
            "    accuracy                         0.7720       943\n",
            "   macro avg     0.7851    0.7614    0.7575       943\n",
            "weighted avg     0.7916    0.7720    0.7690       943\n",
            "\n",
            "12/10/2023 12:12:46 [Dev set] [f1 0.7204]\n",
            "12/10/2023 12:12:46 Save the best model.\n",
            "12/10/2023 12:12:46 [Test set] [f1 0.7690]\n",
            "train epoch 11: 100% 4/4 [00:15<00:00,  3.77s/it]\n",
            "12/10/2023 12:13:01 \n",
            "12/10/2023 12:13:01 [Epoch 11] [Loss: 3.577287] [Time: 15.083529]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.01it/s]\n",
            "test: 100% 1/1 [00:02<00:00,  2.88s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8681    0.5486    0.6723       144\n",
            "         sad     0.7148    0.8898    0.7927       245\n",
            "         neu     0.8446    0.7500    0.7945       384\n",
            "         ang     0.7136    0.8647    0.7819       170\n",
            "\n",
            "    accuracy                         0.7762       943\n",
            "   macro avg     0.7853    0.7633    0.7604       943\n",
            "weighted avg     0.7908    0.7762    0.7731       943\n",
            "\n",
            "12/10/2023 12:13:05 [Dev set] [f1 0.7413]\n",
            "12/10/2023 12:13:05 Save the best model.\n",
            "12/10/2023 12:13:05 [Test set] [f1 0.7731]\n",
            "train epoch 12: 100% 4/4 [00:16<00:00,  4.12s/it]\n",
            "12/10/2023 12:13:22 \n",
            "12/10/2023 12:13:22 [Epoch 12] [Loss: 3.492219] [Time: 16.466700]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.02s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.96s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8617    0.5625    0.6807       144\n",
            "         sad     0.7175    0.9224    0.8071       245\n",
            "         neu     0.8762    0.7370    0.8006       384\n",
            "         ang     0.7156    0.8882    0.7927       170\n",
            "\n",
            "    accuracy                         0.7858       943\n",
            "   macro avg     0.7927    0.7775    0.7703       943\n",
            "weighted avg     0.8038    0.7858    0.7825       943\n",
            "\n",
            "12/10/2023 12:13:26 [Dev set] [f1 0.7502]\n",
            "12/10/2023 12:13:26 Save the best model.\n",
            "12/10/2023 12:13:26 [Test set] [f1 0.7825]\n",
            "train epoch 13: 100% 4/4 [00:15<00:00,  3.90s/it]\n",
            "12/10/2023 12:13:41 \n",
            "12/10/2023 12:13:41 [Epoch 13] [Loss: 3.328423] [Time: 15.612894]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.00s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.63s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8365    0.6042    0.7016       144\n",
            "         sad     0.7082    0.9510    0.8118       245\n",
            "         neu     0.9043    0.7135    0.7977       384\n",
            "         ang     0.7246    0.8824    0.7958       170\n",
            "\n",
            "    accuracy                         0.7890       943\n",
            "   macro avg     0.7934    0.7878    0.7767       943\n",
            "weighted avg     0.8106    0.7890    0.7863       943\n",
            "\n",
            "12/10/2023 12:13:46 [Dev set] [f1 0.7555]\n",
            "12/10/2023 12:13:46 Save the best model.\n",
            "12/10/2023 12:13:46 [Test set] [f1 0.7863]\n",
            "train epoch 14: 100% 4/4 [00:15<00:00,  3.95s/it]\n",
            "12/10/2023 12:14:02 \n",
            "12/10/2023 12:14:02 [Epoch 14] [Loss: 3.371608] [Time: 15.814713]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.01it/s]\n",
            "test: 100% 1/1 [00:02<00:00,  2.95s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8208    0.6042    0.6960       144\n",
            "         sad     0.7112    0.9551    0.8153       245\n",
            "         neu     0.9033    0.7057    0.7924       384\n",
            "         ang     0.7260    0.8882    0.7989       170\n",
            "\n",
            "    accuracy                         0.7879       943\n",
            "   macro avg     0.7903    0.7883    0.7757       943\n",
            "weighted avg     0.8088    0.7879    0.7848       943\n",
            "\n",
            "12/10/2023 12:14:06 [Dev set] [f1 0.7629]\n",
            "12/10/2023 12:14:06 Save the best model.\n",
            "12/10/2023 12:14:06 [Test set] [f1 0.7848]\n",
            "train epoch 15: 100% 4/4 [00:15<00:00,  3.87s/it]\n",
            "12/10/2023 12:14:21 \n",
            "12/10/2023 12:14:21 [Epoch 15] [Loss: 3.065126] [Time: 15.467504]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.24s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.99s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8304    0.6458    0.7266       144\n",
            "         sad     0.7320    0.9143    0.8131       245\n",
            "         neu     0.8785    0.7344    0.8000       384\n",
            "         ang     0.7500    0.9000    0.8182       170\n",
            "\n",
            "    accuracy                         0.7975       943\n",
            "   macro avg     0.7977    0.7986    0.7895       943\n",
            "weighted avg     0.8099    0.7975    0.7955       943\n",
            "\n",
            "12/10/2023 12:14:26 [Dev set] [f1 0.7775]\n",
            "12/10/2023 12:14:26 Save the best model.\n",
            "12/10/2023 12:14:26 [Test set] [f1 0.7955]\n",
            "train epoch 16: 100% 4/4 [00:14<00:00,  3.73s/it]\n",
            "12/10/2023 12:14:41 \n",
            "12/10/2023 12:14:41 [Epoch 16] [Loss: 2.986661] [Time: 14.921494]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.03s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.93s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8034    0.6528    0.7203       144\n",
            "         sad     0.7363    0.9347    0.8237       245\n",
            "         neu     0.8984    0.7135    0.7954       384\n",
            "         ang     0.7381    0.9118    0.8158       170\n",
            "\n",
            "    accuracy                         0.7975       943\n",
            "   macro avg     0.7941    0.8032    0.7888       943\n",
            "weighted avg     0.8129    0.7975    0.7950       943\n",
            "\n",
            "12/10/2023 12:14:45 [Dev set] [f1 0.7753]\n",
            "12/10/2023 12:14:45 [Test set] [f1 0.7950]\n",
            "train epoch 17: 100% 4/4 [00:16<00:00,  4.08s/it]\n",
            "12/10/2023 12:15:01 \n",
            "12/10/2023 12:15:01 [Epoch 17] [Loss: 2.877492] [Time: 16.340400]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.02it/s]\n",
            "test: 100% 1/1 [00:02<00:00,  2.94s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7803    0.7153    0.7464       144\n",
            "         sad     0.7908    0.9102    0.8463       245\n",
            "         neu     0.8765    0.7396    0.8023       384\n",
            "         ang     0.7610    0.9176    0.8320       170\n",
            "\n",
            "    accuracy                         0.8123       943\n",
            "   macro avg     0.8022    0.8207    0.8067       943\n",
            "weighted avg     0.8187    0.8123    0.8105       943\n",
            "\n",
            "12/10/2023 12:15:05 [Dev set] [f1 0.7830]\n",
            "12/10/2023 12:15:05 Save the best model.\n",
            "12/10/2023 12:15:05 [Test set] [f1 0.8105]\n",
            "train epoch 18: 100% 4/4 [00:15<00:00,  3.83s/it]\n",
            "12/10/2023 12:15:21 \n",
            "12/10/2023 12:15:21 [Epoch 18] [Loss: 2.843021] [Time: 15.311394]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.01it/s]\n",
            "test: 100% 1/1 [00:03<00:00,  3.31s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7664    0.7292    0.7473       144\n",
            "         sad     0.7484    0.9592    0.8408       245\n",
            "         neu     0.9125    0.7057    0.7959       384\n",
            "         ang     0.8000    0.9176    0.8548       170\n",
            "\n",
            "    accuracy                         0.8134       943\n",
            "   macro avg     0.8068    0.8279    0.8097       943\n",
            "weighted avg     0.8273    0.8134    0.8108       943\n",
            "\n",
            "12/10/2023 12:15:25 [Dev set] [f1 0.7915]\n",
            "12/10/2023 12:15:25 Save the best model.\n",
            "12/10/2023 12:15:25 [Test set] [f1 0.8108]\n",
            "train epoch 19: 100% 4/4 [00:15<00:00,  3.87s/it]\n",
            "12/10/2023 12:15:41 \n",
            "12/10/2023 12:15:41 [Epoch 19] [Loss: 2.747370] [Time: 15.463642]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.02it/s]\n",
            "test: 100% 1/1 [00:02<00:00,  2.90s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7926    0.7431    0.7670       144\n",
            "         sad     0.8631    0.9265    0.8937       245\n",
            "         neu     0.8761    0.7917    0.8317       384\n",
            "         ang     0.8030    0.9353    0.8641       170\n",
            "\n",
            "    accuracy                         0.8452       943\n",
            "   macro avg     0.8337    0.8491    0.8391       943\n",
            "weighted avg     0.8468    0.8452    0.8438       943\n",
            "\n",
            "12/10/2023 12:15:44 [Dev set] [f1 0.7673]\n",
            "12/10/2023 12:15:44 [Test set] [f1 0.8438]\n",
            "train epoch 20: 100% 4/4 [00:15<00:00,  3.79s/it]\n",
            "12/10/2023 12:16:00 \n",
            "12/10/2023 12:16:00 [Epoch 20] [Loss: 2.747089] [Time: 15.174259]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.04s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.56s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8136    0.6667    0.7328       144\n",
            "         sad     0.7358    0.9551    0.8313       245\n",
            "         neu     0.9028    0.7500    0.8193       384\n",
            "         ang     0.8245    0.9118    0.8659       170\n",
            "\n",
            "    accuracy                         0.8197       943\n",
            "   macro avg     0.8192    0.8209    0.8123       943\n",
            "weighted avg     0.8317    0.8197    0.8176       943\n",
            "\n",
            "12/10/2023 12:16:04 [Dev set] [f1 0.7545]\n",
            "12/10/2023 12:16:04 [Test set] [f1 0.8176]\n",
            "train epoch 21: 100% 4/4 [00:15<00:00,  3.80s/it]\n",
            "12/10/2023 12:16:19 \n",
            "12/10/2023 12:16:19 [Epoch 21] [Loss: 2.593011] [Time: 15.211987]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.93s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7671    0.7778    0.7724       144\n",
            "         sad     0.8537    0.8571    0.8554       245\n",
            "         neu     0.8589    0.7448    0.7978       384\n",
            "         ang     0.7477    0.9588    0.8402       170\n",
            "\n",
            "    accuracy                         0.8176       943\n",
            "   macro avg     0.8068    0.8346    0.8164       943\n",
            "weighted avg     0.8235    0.8176    0.8165       943\n",
            "\n",
            "12/10/2023 12:16:23 [Dev set] [f1 0.7477]\n",
            "12/10/2023 12:16:23 [Test set] [f1 0.8165]\n",
            "train epoch 22: 100% 4/4 [00:15<00:00,  3.93s/it]\n",
            "12/10/2023 12:16:39 \n",
            "12/10/2023 12:16:39 [Epoch 22] [Loss: 2.392242] [Time: 15.708893]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.28s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.98s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7419    0.7986    0.7692       144\n",
            "         sad     0.7905    0.9551    0.8651       245\n",
            "         neu     0.9213    0.6406    0.7558       384\n",
            "         ang     0.7200    0.9529    0.8203       170\n",
            "\n",
            "    accuracy                         0.8028       943\n",
            "   macro avg     0.7935    0.8368    0.8026       943\n",
            "weighted avg     0.8237    0.8028    0.7978       943\n",
            "\n",
            "12/10/2023 12:16:43 [Dev set] [f1 0.7971]\n",
            "12/10/2023 12:16:44 Save the best model.\n",
            "12/10/2023 12:16:44 [Test set] [f1 0.7978]\n",
            "train epoch 23: 100% 4/4 [00:15<00:00,  3.89s/it]\n",
            "12/10/2023 12:16:59 \n",
            "12/10/2023 12:16:59 [Epoch 23] [Loss: 2.224836] [Time: 15.579132]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.02s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.94s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7744    0.7153    0.7437       144\n",
            "         sad     0.8273    0.9388    0.8795       245\n",
            "         neu     0.8711    0.7917    0.8295       384\n",
            "         ang     0.8361    0.9000    0.8669       170\n",
            "\n",
            "    accuracy                         0.8378       943\n",
            "   macro avg     0.8272    0.8364    0.8299       943\n",
            "weighted avg     0.8386    0.8378    0.8361       943\n",
            "\n",
            "12/10/2023 12:17:03 [Dev set] [f1 0.7518]\n",
            "12/10/2023 12:17:03 [Test set] [f1 0.8361]\n",
            "train epoch 24: 100% 4/4 [00:17<00:00,  4.27s/it]\n",
            "12/10/2023 12:17:20 \n",
            "12/10/2023 12:17:20 [Epoch 24] [Loss: 2.206539] [Time: 17.069940]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.01it/s]\n",
            "test: 100% 1/1 [00:02<00:00,  2.96s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7714    0.7500    0.7606       144\n",
            "         sad     0.8321    0.9510    0.8876       245\n",
            "         neu     0.8967    0.7005    0.7865       384\n",
            "         ang     0.7085    0.9294    0.8041       170\n",
            "\n",
            "    accuracy                         0.8144       943\n",
            "   macro avg     0.8022    0.8327    0.8097       943\n",
            "weighted avg     0.8269    0.8144    0.8120       943\n",
            "\n",
            "12/10/2023 12:17:24 [Dev set] [f1 0.7547]\n",
            "12/10/2023 12:17:24 [Test set] [f1 0.8120]\n",
            "train epoch 25: 100% 4/4 [00:16<00:00,  4.03s/it]\n",
            "12/10/2023 12:17:40 \n",
            "12/10/2023 12:17:40 [Epoch 25] [Loss: 2.043687] [Time: 16.112881]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.04it/s]\n",
            "test: 100% 1/1 [00:03<00:00,  3.50s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.6667    0.8889    0.7619       144\n",
            "         sad     0.8300    0.8571    0.8434       245\n",
            "         neu     0.9122    0.7031    0.7941       384\n",
            "         ang     0.7673    0.9118    0.8333       170\n",
            "\n",
            "    accuracy                         0.8091       943\n",
            "   macro avg     0.7940    0.8402    0.8082       943\n",
            "weighted avg     0.8272    0.8091    0.8091       943\n",
            "\n",
            "12/10/2023 12:17:45 [Dev set] [f1 0.8003]\n",
            "12/10/2023 12:17:45 Save the best model.\n",
            "12/10/2023 12:17:45 [Test set] [f1 0.8091]\n",
            "train epoch 26: 100% 4/4 [00:15<00:00,  3.87s/it]\n",
            "12/10/2023 12:18:00 \n",
            "12/10/2023 12:18:00 [Epoch 26] [Loss: 2.100347] [Time: 15.463591]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.00s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.92s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8140    0.7292    0.7692       144\n",
            "         sad     0.7972    0.9143    0.8517       245\n",
            "         neu     0.8779    0.6927    0.7744       384\n",
            "         ang     0.6913    0.9353    0.7950       170\n",
            "\n",
            "    accuracy                         0.7996       943\n",
            "   macro avg     0.7951    0.8179    0.7976       943\n",
            "weighted avg     0.8135    0.7996    0.7974       943\n",
            "\n",
            "12/10/2023 12:18:04 [Dev set] [f1 0.7229]\n",
            "12/10/2023 12:18:04 [Test set] [f1 0.7974]\n",
            "train epoch 27: 100% 4/4 [00:15<00:00,  3.97s/it]\n",
            "12/10/2023 12:18:20 \n",
            "12/10/2023 12:18:20 [Epoch 27] [Loss: 1.925314] [Time: 15.878100]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.28s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.09s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7883    0.7500    0.7687       144\n",
            "         sad     0.8529    0.8286    0.8406       245\n",
            "         neu     0.8347    0.7891    0.8112       384\n",
            "         ang     0.7707    0.9294    0.8427       170\n",
            "\n",
            "    accuracy                         0.8187       943\n",
            "   macro avg     0.8117    0.8243    0.8158       943\n",
            "weighted avg     0.8208    0.8187    0.8180       943\n",
            "\n",
            "12/10/2023 12:18:25 [Dev set] [f1 0.7690]\n",
            "12/10/2023 12:18:25 [Test set] [f1 0.8180]\n",
            "train epoch 28: 100% 4/4 [00:15<00:00,  3.93s/it]\n",
            "12/10/2023 12:18:40 \n",
            "12/10/2023 12:18:40 [Epoch 28] [Loss: 1.801186] [Time: 15.711147]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.00s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.11s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.6923    0.8750    0.7730       144\n",
            "         sad     0.8102    0.9061    0.8555       245\n",
            "         neu     0.9158    0.6510    0.7610       384\n",
            "         ang     0.7430    0.9353    0.8281       170\n",
            "\n",
            "    accuracy                         0.8028       943\n",
            "   macro avg     0.7903    0.8419    0.8044       943\n",
            "weighted avg     0.8231    0.8028    0.7995       943\n",
            "\n",
            "12/10/2023 12:18:44 [Dev set] [f1 0.7683]\n",
            "12/10/2023 12:18:44 [Test set] [f1 0.7995]\n",
            "train epoch 29: 100% 4/4 [00:16<00:00,  4.06s/it]\n",
            "12/10/2023 12:19:01 \n",
            "12/10/2023 12:19:01 [Epoch 29] [Loss: 1.850715] [Time: 16.256259]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.00s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.93s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7721    0.7292    0.7500       144\n",
            "         sad     0.8619    0.8408    0.8512       245\n",
            "         neu     0.8347    0.8151    0.8248       384\n",
            "         ang     0.7979    0.9059    0.8485       170\n",
            "\n",
            "    accuracy                         0.8250       943\n",
            "   macro avg     0.8166    0.8227    0.8186       943\n",
            "weighted avg     0.8256    0.8250    0.8245       943\n",
            "\n",
            "12/10/2023 12:19:05 [Dev set] [f1 0.7742]\n",
            "12/10/2023 12:19:05 [Test set] [f1 0.8245]\n",
            "train epoch 30: 100% 4/4 [00:15<00:00,  3.97s/it]\n",
            "12/10/2023 12:19:21 \n",
            "12/10/2023 12:19:21 [Epoch 30] [Loss: 1.765821] [Time: 15.898627]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.50s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7517    0.7778    0.7645       144\n",
            "         sad     0.8222    0.9061    0.8621       245\n",
            "         neu     0.8975    0.6615    0.7616       384\n",
            "         ang     0.6680    0.9471    0.7835       170\n",
            "\n",
            "    accuracy                         0.7943       943\n",
            "   macro avg     0.7849    0.8231    0.7929       943\n",
            "weighted avg     0.8143    0.7943    0.7921       943\n",
            "\n",
            "12/10/2023 12:19:25 [Dev set] [f1 0.7635]\n",
            "12/10/2023 12:19:25 [Test set] [f1 0.7921]\n",
            "train epoch 31: 100% 4/4 [00:15<00:00,  3.84s/it]\n",
            "12/10/2023 12:19:40 \n",
            "12/10/2023 12:19:40 [Epoch 31] [Loss: 1.691049] [Time: 15.365884]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.02s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.97s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7093    0.8472    0.7722       144\n",
            "         sad     0.8930    0.7837    0.8348       245\n",
            "         neu     0.8280    0.8021    0.8148       384\n",
            "         ang     0.8207    0.8882    0.8531       170\n",
            "\n",
            "    accuracy                         0.8197       943\n",
            "   macro avg     0.8127    0.8303    0.8187       943\n",
            "weighted avg     0.8254    0.8197    0.8204       943\n",
            "\n",
            "12/10/2023 12:19:44 [Dev set] [f1 0.8139]\n",
            "12/10/2023 12:19:45 Save the best model.\n",
            "12/10/2023 12:19:45 [Test set] [f1 0.8204]\n",
            "train epoch 32: 100% 4/4 [00:15<00:00,  3.97s/it]\n",
            "12/10/2023 12:20:01 \n",
            "12/10/2023 12:20:01 [Epoch 32] [Loss: 1.462760] [Time: 15.889178]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.27s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.16s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7986    0.7708    0.7845       144\n",
            "         sad     0.7756    0.9592    0.8577       245\n",
            "         neu     0.9135    0.6875    0.7845       384\n",
            "         ang     0.7358    0.9176    0.8168       170\n",
            "\n",
            "    accuracy                         0.8123       943\n",
            "   macro avg     0.8059    0.8338    0.8109       943\n",
            "weighted avg     0.8281    0.8123    0.8093       943\n",
            "\n",
            "12/10/2023 12:20:05 [Dev set] [f1 0.7643]\n",
            "12/10/2023 12:20:05 [Test set] [f1 0.8093]\n",
            "train epoch 33: 100% 4/4 [00:16<00:00,  4.01s/it]\n",
            "12/10/2023 12:20:21 \n",
            "12/10/2023 12:20:21 [Epoch 33] [Loss: 1.506264] [Time: 16.024923]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.03it/s]\n",
            "test: 100% 1/1 [00:02<00:00,  2.94s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8226    0.7083    0.7612       144\n",
            "         sad     0.8857    0.7592    0.8176       245\n",
            "         neu     0.7800    0.8125    0.7959       384\n",
            "         ang     0.7416    0.9118    0.8179       170\n",
            "\n",
            "    accuracy                         0.8006       943\n",
            "   macro avg     0.8075    0.7979    0.7982       943\n",
            "weighted avg     0.8071    0.8006    0.8002       943\n",
            "\n",
            "12/10/2023 12:20:25 [Dev set] [f1 0.7758]\n",
            "12/10/2023 12:20:25 [Test set] [f1 0.8002]\n",
            "train epoch 34: 100% 4/4 [00:15<00:00,  3.90s/it]\n",
            "12/10/2023 12:20:41 \n",
            "12/10/2023 12:20:41 [Epoch 34] [Loss: 1.394521] [Time: 15.586833]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.01it/s]\n",
            "test: 100% 1/1 [00:02<00:00,  3.00s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.6543    0.8542    0.7410       144\n",
            "         sad     0.7605    0.9592    0.8484       245\n",
            "         neu     0.9106    0.5833    0.7111       384\n",
            "         ang     0.7550    0.8882    0.8162       170\n",
            "\n",
            "    accuracy                         0.7773       943\n",
            "   macro avg     0.7701    0.8212    0.7792       943\n",
            "weighted avg     0.8044    0.7773    0.7703       943\n",
            "\n",
            "12/10/2023 12:20:45 [Dev set] [f1 0.7532]\n",
            "12/10/2023 12:20:45 [Test set] [f1 0.7703]\n",
            "train epoch 35: 100% 4/4 [00:15<00:00,  3.91s/it]\n",
            "12/10/2023 12:21:00 \n",
            "12/10/2023 12:21:00 [Epoch 35] [Loss: 1.550945] [Time: 15.659778]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.00s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.41s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8318    0.6181    0.7092       144\n",
            "         sad     0.8756    0.7755    0.8225       245\n",
            "         neu     0.7704    0.8125    0.7909       384\n",
            "         ang     0.7243    0.9118    0.8073       170\n",
            "\n",
            "    accuracy                         0.7911       943\n",
            "   macro avg     0.8005    0.7795    0.7825       943\n",
            "weighted avg     0.7988    0.7911    0.7896       943\n",
            "\n",
            "12/10/2023 12:21:05 [Dev set] [f1 0.7879]\n",
            "12/10/2023 12:21:05 [Test set] [f1 0.7896]\n",
            "train epoch 36: 100% 4/4 [00:16<00:00,  4.02s/it]\n",
            "12/10/2023 12:21:21 \n",
            "12/10/2023 12:21:21 [Epoch 36] [Loss: 1.277370] [Time: 16.093251]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.92s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7829    0.8264    0.8041       144\n",
            "         sad     0.8217    0.8653    0.8429       245\n",
            "         neu     0.8803    0.6510    0.7485       384\n",
            "         ang     0.6345    0.9294    0.7542       170\n",
            "\n",
            "    accuracy                         0.7837       943\n",
            "   macro avg     0.7799    0.8180    0.7874       943\n",
            "weighted avg     0.8059    0.7837    0.7825       943\n",
            "\n",
            "12/10/2023 12:21:25 [Dev set] [f1 0.7956]\n",
            "12/10/2023 12:21:25 [Test set] [f1 0.7825]\n",
            "train epoch 37: 100% 4/4 [00:15<00:00,  3.92s/it]\n",
            "12/10/2023 12:21:40 \n",
            "12/10/2023 12:21:40 [Epoch 37] [Loss: 1.332399] [Time: 15.685699]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.30s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.15s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7881    0.8264    0.8068       144\n",
            "         sad     0.8188    0.9224    0.8676       245\n",
            "         neu     0.9016    0.7161    0.7983       384\n",
            "         ang     0.7393    0.9176    0.8189       170\n",
            "\n",
            "    accuracy                         0.8229       943\n",
            "   macro avg     0.8120    0.8457    0.8229       943\n",
            "weighted avg     0.8335    0.8229    0.8213       943\n",
            "\n",
            "12/10/2023 12:21:45 [Dev set] [f1 0.8279]\n",
            "12/10/2023 12:21:45 Save the best model.\n",
            "12/10/2023 12:21:45 [Test set] [f1 0.8213]\n",
            "train epoch 38: 100% 4/4 [00:16<00:00,  4.07s/it]\n",
            "12/10/2023 12:22:01 \n",
            "12/10/2023 12:22:01 [Epoch 38] [Loss: 1.134108] [Time: 16.263680]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.03s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.08s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8250    0.6875    0.7500       144\n",
            "         sad     0.8805    0.8122    0.8450       245\n",
            "         neu     0.8089    0.8047    0.8068       384\n",
            "         ang     0.7395    0.9353    0.8260       170\n",
            "\n",
            "    accuracy                         0.8123       943\n",
            "   macro avg     0.8135    0.8099    0.8069       943\n",
            "weighted avg     0.8175    0.8123    0.8115       943\n",
            "\n",
            "12/10/2023 12:22:05 [Dev set] [f1 0.8183]\n",
            "12/10/2023 12:22:05 [Test set] [f1 0.8115]\n",
            "train epoch 39: 100% 4/4 [00:16<00:00,  4.06s/it]\n",
            "12/10/2023 12:22:22 \n",
            "12/10/2023 12:22:22 [Epoch 39] [Loss: 1.154860] [Time: 16.230984]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.29s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7421    0.8194    0.7789       144\n",
            "         sad     0.8125    0.9020    0.8549       245\n",
            "         neu     0.8889    0.6875    0.7753       384\n",
            "         ang     0.7302    0.9235    0.8156       170\n",
            "\n",
            "    accuracy                         0.8059       943\n",
            "   macro avg     0.7934    0.8331    0.8062       943\n",
            "weighted avg     0.8180    0.8059    0.8038       943\n",
            "\n",
            "12/10/2023 12:22:26 [Dev set] [f1 0.7670]\n",
            "12/10/2023 12:22:26 [Test set] [f1 0.8038]\n",
            "train epoch 40: 100% 4/4 [00:15<00:00,  3.79s/it]\n",
            "12/10/2023 12:22:41 \n",
            "12/10/2023 12:22:41 [Epoch 40] [Loss: 1.207553] [Time: 15.168073]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.47s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7000    0.8264    0.7580       144\n",
            "         sad     0.8520    0.7755    0.8120       245\n",
            "         neu     0.8245    0.6849    0.7482       384\n",
            "         ang     0.6840    0.9294    0.7880       170\n",
            "\n",
            "    accuracy                         0.7741       943\n",
            "   macro avg     0.7651    0.8041    0.7765       943\n",
            "weighted avg     0.7873    0.7741    0.7734       943\n",
            "\n",
            "12/10/2023 12:22:46 [Dev set] [f1 0.8113]\n",
            "12/10/2023 12:22:46 [Test set] [f1 0.7734]\n",
            "train epoch 41: 100% 4/4 [00:15<00:00,  3.92s/it]\n",
            "12/10/2023 12:23:01 \n",
            "12/10/2023 12:23:01 [Epoch 41] [Loss: 1.121143] [Time: 15.662680]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.00it/s]\n",
            "test: 100% 1/1 [00:02<00:00,  2.93s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8077    0.7292    0.7664       144\n",
            "         sad     0.8750    0.8286    0.8512       245\n",
            "         neu     0.8082    0.8229    0.8155       384\n",
            "         ang     0.8053    0.9000    0.8500       170\n",
            "\n",
            "    accuracy                         0.8240       943\n",
            "   macro avg     0.8240    0.8202    0.8208       943\n",
            "weighted avg     0.8249    0.8240    0.8235       943\n",
            "\n",
            "12/10/2023 12:23:05 [Dev set] [f1 0.8189]\n",
            "12/10/2023 12:23:05 [Test set] [f1 0.8235]\n",
            "train epoch 42: 100% 4/4 [00:16<00:00,  4.11s/it]\n",
            "12/10/2023 12:23:22 \n",
            "12/10/2023 12:23:22 [Epoch 42] [Loss: 1.034778] [Time: 16.423338]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.21s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.14s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7654    0.8611    0.8105       144\n",
            "         sad     0.8430    0.8327    0.8378       245\n",
            "         neu     0.8806    0.7109    0.7867       384\n",
            "         ang     0.6856    0.9235    0.7870       170\n",
            "\n",
            "    accuracy                         0.8038       943\n",
            "   macro avg     0.7937    0.8321    0.8055       943\n",
            "weighted avg     0.8181    0.8038    0.8037       943\n",
            "\n",
            "12/10/2023 12:23:26 [Dev set] [f1 0.8170]\n",
            "12/10/2023 12:23:26 [Test set] [f1 0.8037]\n",
            "train epoch 43: 100% 4/4 [00:15<00:00,  3.98s/it]\n",
            "12/10/2023 12:23:42 \n",
            "12/10/2023 12:23:42 [Epoch 43] [Loss: 0.898601] [Time: 15.910954]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.14s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.29s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7750    0.8611    0.8158       144\n",
            "         sad     0.8517    0.8204    0.8358       245\n",
            "         neu     0.8810    0.7135    0.7885       384\n",
            "         ang     0.6780    0.9412    0.7882       170\n",
            "\n",
            "    accuracy                         0.8049       943\n",
            "   macro avg     0.7964    0.8341    0.8071       943\n",
            "weighted avg     0.8206    0.8049    0.8049       943\n",
            "\n",
            "12/10/2023 12:23:46 [Dev set] [f1 0.8073]\n",
            "12/10/2023 12:23:46 [Test set] [f1 0.8049]\n",
            "train epoch 44: 100% 4/4 [00:15<00:00,  3.97s/it]\n",
            "12/10/2023 12:24:02 \n",
            "12/10/2023 12:24:02 [Epoch 44] [Loss: 0.983439] [Time: 15.886095]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "test: 100% 1/1 [00:02<00:00,  2.97s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7785    0.8542    0.8146       144\n",
            "         sad     0.8547    0.8163    0.8351       245\n",
            "         neu     0.8715    0.7240    0.7909       384\n",
            "         ang     0.6853    0.9353    0.7910       170\n",
            "\n",
            "    accuracy                         0.8059       943\n",
            "   macro avg     0.7975    0.8324    0.8079       943\n",
            "weighted avg     0.8194    0.8059    0.8060       943\n",
            "\n",
            "12/10/2023 12:24:06 [Dev set] [f1 0.8095]\n",
            "12/10/2023 12:24:06 [Test set] [f1 0.8060]\n",
            "train epoch 45: 100% 4/4 [00:15<00:00,  3.77s/it]\n",
            "12/10/2023 12:24:21 \n",
            "12/10/2023 12:24:21 [Epoch 45] [Loss: 0.929385] [Time: 15.095869]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.03s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.52s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7987    0.8264    0.8123       144\n",
            "         sad     0.8541    0.8122    0.8326       245\n",
            "         neu     0.8592    0.7630    0.8083       384\n",
            "         ang     0.7182    0.9294    0.8103       170\n",
            "\n",
            "    accuracy                         0.8155       943\n",
            "   macro avg     0.8075    0.8328    0.8159       943\n",
            "weighted avg     0.8232    0.8155    0.8156       943\n",
            "\n",
            "12/10/2023 12:24:26 [Dev set] [f1 0.8174]\n",
            "12/10/2023 12:24:26 [Test set] [f1 0.8156]\n",
            "train epoch 46: 100% 4/4 [00:16<00:00,  4.04s/it]\n",
            "12/10/2023 12:24:42 \n",
            "12/10/2023 12:24:42 [Epoch 46] [Loss: 0.882533] [Time: 16.175055]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.01it/s]\n",
            "test: 100% 1/1 [00:03<00:00,  3.23s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7931    0.7986    0.7958       144\n",
            "         sad     0.8534    0.8082    0.8302       245\n",
            "         neu     0.8414    0.7734    0.8060       384\n",
            "         ang     0.7277    0.9118    0.8094       170\n",
            "\n",
            "    accuracy                         0.8112       943\n",
            "   macro avg     0.8039    0.8230    0.8104       943\n",
            "weighted avg     0.8166    0.8112    0.8113       943\n",
            "\n",
            "12/10/2023 12:24:46 [Dev set] [f1 0.8130]\n",
            "12/10/2023 12:24:46 [Test set] [f1 0.8113]\n",
            "train epoch 47: 100% 4/4 [00:16<00:00,  4.23s/it]\n",
            "12/10/2023 12:25:03 \n",
            "12/10/2023 12:25:03 [Epoch 47] [Loss: 0.960729] [Time: 16.938691]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.00s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.13s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7823    0.7986    0.7904       144\n",
            "         sad     0.8523    0.8245    0.8382       245\n",
            "         neu     0.8486    0.7734    0.8093       384\n",
            "         ang     0.7416    0.9118    0.8179       170\n",
            "\n",
            "    accuracy                         0.8155       943\n",
            "   macro avg     0.8062    0.8271    0.8139       943\n",
            "weighted avg     0.8201    0.8155    0.8155       943\n",
            "\n",
            "12/10/2023 12:25:07 [Dev set] [f1 0.8201]\n",
            "12/10/2023 12:25:07 [Test set] [f1 0.8155]\n",
            "train epoch 48: 100% 4/4 [00:15<00:00,  3.88s/it]\n",
            "12/10/2023 12:25:23 \n",
            "12/10/2023 12:25:23 [Epoch 48] [Loss: 1.033371] [Time: 15.528371]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.02s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.63s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7532    0.8264    0.7881       144\n",
            "         sad     0.8415    0.8449    0.8432       245\n",
            "         neu     0.8634    0.7240    0.7875       384\n",
            "         ang     0.7189    0.9176    0.8062       170\n",
            "\n",
            "    accuracy                         0.8059       943\n",
            "   macro avg     0.7942    0.8282    0.8062       943\n",
            "weighted avg     0.8148    0.8059    0.8054       943\n",
            "\n",
            "12/10/2023 12:25:27 [Dev set] [f1 0.8275]\n",
            "12/10/2023 12:25:27 [Test set] [f1 0.8054]\n",
            "train epoch 49: 100% 4/4 [00:16<00:00,  4.17s/it]\n",
            "12/10/2023 12:25:44 \n",
            "12/10/2023 12:25:44 [Epoch 49] [Loss: 0.910613] [Time: 16.697610]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.02s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.11s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7485    0.8472    0.7948       144\n",
            "         sad     0.8410    0.8204    0.8306       245\n",
            "         neu     0.8631    0.7057    0.7765       384\n",
            "         ang     0.6960    0.9294    0.7960       170\n",
            "\n",
            "    accuracy                         0.7975       943\n",
            "   macro avg     0.7871    0.8257    0.7995       943\n",
            "weighted avg     0.8097    0.7975    0.7969       943\n",
            "\n",
            "12/10/2023 12:25:48 [Dev set] [f1 0.8304]\n",
            "12/10/2023 12:25:49 Save the best model.\n",
            "12/10/2023 12:25:49 [Test set] [f1 0.7969]\n",
            "train epoch 50: 100% 4/4 [00:17<00:00,  4.30s/it]\n",
            "12/10/2023 12:26:06 \n",
            "12/10/2023 12:26:06 [Epoch 50] [Loss: 0.831836] [Time: 17.208035]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.04s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.19s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7151    0.8542    0.7785       144\n",
            "         sad     0.8250    0.8082    0.8165       245\n",
            "         neu     0.8707    0.6667    0.7552       384\n",
            "         ang     0.6751    0.9412    0.7862       170\n",
            "\n",
            "    accuracy                         0.7815       943\n",
            "   macro avg     0.7715    0.8175    0.7841       943\n",
            "weighted avg     0.7998    0.7815    0.7803       943\n",
            "\n",
            "12/10/2023 12:26:10 [Dev set] [f1 0.8138]\n",
            "12/10/2023 12:26:10 [Test set] [f1 0.7803]\n",
            "train epoch 51: 100% 4/4 [00:15<00:00,  4.00s/it]\n",
            "12/10/2023 12:26:26 \n",
            "12/10/2023 12:26:26 [Epoch 51] [Loss: 0.788650] [Time: 15.997591]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.02s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.51s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7289    0.8403    0.7806       144\n",
            "         sad     0.8390    0.8082    0.8233       245\n",
            "         neu     0.8713    0.6875    0.7686       384\n",
            "         ang     0.6765    0.9471    0.7892       170\n",
            "\n",
            "    accuracy                         0.7890       943\n",
            "   macro avg     0.7789    0.8207    0.7904       943\n",
            "weighted avg     0.8060    0.7890    0.7883       943\n",
            "\n",
            "12/10/2023 12:26:30 [Dev set] [f1 0.8111]\n",
            "12/10/2023 12:26:30 [Test set] [f1 0.7883]\n",
            "train epoch 52: 100% 4/4 [00:16<00:00,  4.15s/it]\n",
            "12/10/2023 12:26:47 \n",
            "12/10/2023 12:26:47 [Epoch 52] [Loss: 0.882729] [Time: 16.609941]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.01s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.09s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7453    0.8333    0.7869       144\n",
            "         sad     0.8462    0.8082    0.8267       245\n",
            "         neu     0.8698    0.7135    0.7840       384\n",
            "         ang     0.6910    0.9471    0.7990       170\n",
            "\n",
            "    accuracy                         0.7985       943\n",
            "   macro avg     0.7881    0.8255    0.7991       943\n",
            "weighted avg     0.8124    0.7985    0.7982       943\n",
            "\n",
            "12/10/2023 12:26:51 [Dev set] [f1 0.8066]\n",
            "12/10/2023 12:26:51 [Test set] [f1 0.7982]\n",
            "train epoch 53: 100% 4/4 [00:17<00:00,  4.32s/it]\n",
            "12/10/2023 12:27:08 \n",
            "12/10/2023 12:27:08 [Epoch 53] [Loss: 0.901984] [Time: 17.269154]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.14s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.29s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7566    0.7986    0.7770       144\n",
            "         sad     0.8475    0.8163    0.8316       245\n",
            "         neu     0.8532    0.7266    0.7848       384\n",
            "         ang     0.7061    0.9471    0.8090       170\n",
            "\n",
            "    accuracy                         0.8006       943\n",
            "   macro avg     0.7908    0.8221    0.8006       943\n",
            "weighted avg     0.8104    0.8006    0.8001       943\n",
            "\n",
            "12/10/2023 12:27:13 [Dev set] [f1 0.8124]\n",
            "12/10/2023 12:27:13 [Test set] [f1 0.8001]\n",
            "train epoch 54: 100% 4/4 [00:17<00:00,  4.28s/it]\n",
            "12/10/2023 12:27:30 \n",
            "12/10/2023 12:27:30 [Epoch 54] [Loss: 0.807013] [Time: 17.124891]\n",
            "dev: 100% 1/1 [00:01<00:00,  1.66s/it]\n",
            "test: 100% 1/1 [00:03<00:00,  3.36s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7582    0.8056    0.7811       144\n",
            "         sad     0.8445    0.8204    0.8323       245\n",
            "         neu     0.8528    0.7240    0.7831       384\n",
            "         ang     0.7080    0.9412    0.8081       170\n",
            "\n",
            "    accuracy                         0.8006       943\n",
            "   macro avg     0.7909    0.8228    0.8012       943\n",
            "weighted avg     0.8101    0.8006    0.8001       943\n",
            "\n",
            "12/10/2023 12:27:35 [Dev set] [f1 0.8124]\n",
            "12/10/2023 12:27:35 [Test set] [f1 0.8001]\n",
            "train epoch 55: 100% 4/4 [00:16<00:00,  4.17s/it]\n",
            "12/10/2023 12:27:52 \n",
            "12/10/2023 12:27:52 [Epoch 55] [Loss: 0.847455] [Time: 16.691870]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.00it/s]\n",
            "test: 100% 1/1 [00:03<00:00,  3.06s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7582    0.8056    0.7811       144\n",
            "         sad     0.8382    0.8245    0.8313       245\n",
            "         neu     0.8571    0.7188    0.7819       384\n",
            "         ang     0.7048    0.9412    0.8060       170\n",
            "\n",
            "    accuracy                         0.7996       943\n",
            "   macro avg     0.7896    0.8225    0.8001       943\n",
            "weighted avg     0.8096    0.7996    0.7990       943\n",
            "\n",
            "12/10/2023 12:27:56 [Dev set] [f1 0.8124]\n",
            "12/10/2023 12:27:56 [Test set] [f1 0.7990]\n",
            "12/10/2023 12:27:56 \n",
            "12/10/2023 12:27:56 Best in epoch 49:\n",
            "dev: 100% 1/1 [00:01<00:00,  1.33s/it]\n",
            "12/10/2023 12:27:57 [Dev set] [f1 0.8304]\n",
            "test: 100% 1/1 [00:03<00:00,  3.12s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.7485    0.8472    0.7948       144\n",
            "         sad     0.8410    0.8204    0.8306       245\n",
            "         neu     0.8631    0.7057    0.7765       384\n",
            "         ang     0.6960    0.9294    0.7960       170\n",
            "\n",
            "    accuracy                         0.7975       943\n",
            "   macro avg     0.7871    0.8257    0.7995       943\n",
            "weighted avg     0.8097    0.7975    0.7969       943\n",
            "\n",
            "12/10/2023 12:28:00 [Test set] f1 0.7968544632328719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVALUATION Part 1\n",
        "\n",
        "Evaluating the model trained above."
      ],
      "metadata": {
        "id": "eJrSYzG1I_SX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval.py --dataset=\"iemocap_4\" --modalities=\"atv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YqPqwuLI-1J",
        "outputId": "fab2949b-2825-4b3b-ba9f-9368a6da7b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test: 100% 1/1 [00:01<00:00,  1.63s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7485    0.8472    0.7948       144\n",
            "           1     0.8410    0.8204    0.8306       245\n",
            "           2     0.8631    0.7057    0.7765       384\n",
            "           3     0.6960    0.9294    0.7960       170\n",
            "\n",
            "    accuracy                         0.7975       943\n",
            "   macro avg     0.7871    0.8257    0.7995       943\n",
            "weighted avg     0.8097    0.7975    0.7969       943\n",
            "\n",
            "F1 Score: 0.7968544632328719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Finetuning\n",
        "\n",
        "Modalities: atv\n",
        "\n",
        "Epochs: 10\n",
        "\n",
        "Window Past: [1-2-4-5-6-7-9-10-11-15]\n",
        "\n",
        "Window Future: [1-2-4-5-6-7-9-10-11-15]"
      ],
      "metadata": {
        "id": "mq2aHG5ruqQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataset=\"iemocap_4\" --modalities=\"atv\" --from_begin --epochs=10 --wp=4 --wf=4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjUoBpEmvIz5",
        "outputId": "fbcb28ef-507e-4b9e-a118-8e7e32d7d193"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed set\n",
            "12/12/2023 06:36:52 Loaded data.\n",
            "SeqContext-> USING Transformer\n",
            "args.drop_rate: 0.5\n",
            "Using Scheduler\n",
            "12/12/2023 06:36:54 Start training...\n",
            "train epoch 1: 100% 4/4 [00:02<00:00,  1.69it/s]\n",
            "12/12/2023 06:36:56 \n",
            "12/12/2023 06:36:56 [Epoch 1] [Loss: 5.486128] [Time: 2.372018]\n",
            "dev: 100% 1/1 [00:00<00:00,  2.60it/s]\n",
            "test: 100% 1/1 [00:00<00:00,  1.19it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.0000    0.0000    0.0000       144\n",
            "         sad     0.4279    0.7388    0.5419       245\n",
            "         neu     0.4735    0.3255    0.3858       384\n",
            "         ang     0.4648    0.7000    0.5587       170\n",
            "\n",
            "    accuracy                         0.4507       943\n",
            "   macro avg     0.3416    0.4411    0.3716       943\n",
            "weighted avg     0.3878    0.4507    0.3986       943\n",
            "\n",
            "12/12/2023 06:36:57 [Dev set] [f1 0.4298]\n",
            "12/12/2023 06:36:58 Save the best model.\n",
            "12/12/2023 06:36:58 [Test set] [f1 0.3986]\n",
            "train epoch 2: 100% 4/4 [00:01<00:00,  2.03it/s]\n",
            "12/12/2023 06:37:00 \n",
            "12/12/2023 06:37:00 [Epoch 2] [Loss: 5.088597] [Time: 1.969037]\n",
            "dev: 100% 1/1 [00:00<00:00,  1.93it/s]\n",
            "test: 100% 1/1 [00:01<00:00,  1.26s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.0000    0.0000    0.0000       144\n",
            "         sad     0.5711    0.9020    0.6994       245\n",
            "         neu     0.6768    0.5234    0.5903       384\n",
            "         ang     0.5444    0.8294    0.6573       170\n",
            "\n",
            "    accuracy                         0.5970       943\n",
            "   macro avg     0.4481    0.5637    0.4868       943\n",
            "weighted avg     0.5221    0.5970    0.5406       943\n",
            "\n",
            "12/12/2023 06:37:01 [Dev set] [f1 0.4966]\n",
            "12/12/2023 06:37:02 Save the best model.\n",
            "12/12/2023 06:37:02 [Test set] [f1 0.5406]\n",
            "train epoch 3: 100% 4/4 [00:02<00:00,  1.90it/s]\n",
            "12/12/2023 06:37:04 \n",
            "12/12/2023 06:37:04 [Epoch 3] [Loss: 4.749451] [Time: 2.110317]\n",
            "dev: 100% 1/1 [00:00<00:00,  2.68it/s]\n",
            "test: 100% 1/1 [00:00<00:00,  1.19it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8421    0.1111    0.1963       144\n",
            "         sad     0.5921    0.9184    0.7200       245\n",
            "         neu     0.7264    0.6016    0.6581       384\n",
            "         ang     0.6504    0.8647    0.7424       170\n",
            "\n",
            "    accuracy                         0.6564       943\n",
            "   macro avg     0.7028    0.6239    0.5792       943\n",
            "weighted avg     0.6955    0.6564    0.6189       943\n",
            "\n",
            "12/12/2023 06:37:05 [Dev set] [f1 0.5385]\n",
            "12/12/2023 06:37:05 Save the best model.\n",
            "12/12/2023 06:37:05 [Test set] [f1 0.6189]\n",
            "train epoch 4: 100% 4/4 [00:01<00:00,  2.23it/s]\n",
            "12/12/2023 06:37:07 \n",
            "12/12/2023 06:37:07 [Epoch 4] [Loss: 4.527344] [Time: 1.795871]\n",
            "dev: 100% 1/1 [00:00<00:00,  2.74it/s]\n",
            "test: 100% 1/1 [00:00<00:00,  1.17it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.9286    0.2708    0.4194       144\n",
            "         sad     0.6580    0.9347    0.7723       245\n",
            "         neu     0.7937    0.6615    0.7216       384\n",
            "         ang     0.6481    0.8882    0.7494       170\n",
            "\n",
            "    accuracy                         0.7137       943\n",
            "   macro avg     0.7571    0.6888    0.6657       943\n",
            "weighted avg     0.7528    0.7137    0.6936       943\n",
            "\n",
            "12/12/2023 06:37:08 [Dev set] [f1 0.6065]\n",
            "12/12/2023 06:37:08 Save the best model.\n",
            "12/12/2023 06:37:08 [Test set] [f1 0.6936]\n",
            "train epoch 5: 100% 4/4 [00:01<00:00,  2.28it/s]\n",
            "12/12/2023 06:37:10 \n",
            "12/12/2023 06:37:10 [Epoch 5] [Loss: 4.344490] [Time: 1.753184]\n",
            "dev: 100% 1/1 [00:00<00:00,  2.68it/s]\n",
            "test: 100% 1/1 [00:00<00:00,  1.19it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.9434    0.3472    0.5076       144\n",
            "         sad     0.6842    0.9020    0.7782       245\n",
            "         neu     0.8131    0.6797    0.7404       384\n",
            "         ang     0.6220    0.9000    0.7356       170\n",
            "\n",
            "    accuracy                         0.7264       943\n",
            "   macro avg     0.7657    0.7072    0.6904       943\n",
            "weighted avg     0.7650    0.7264    0.7138       943\n",
            "\n",
            "12/12/2023 06:37:11 [Dev set] [f1 0.5892]\n",
            "12/12/2023 06:37:11 [Test set] [f1 0.7138]\n",
            "train epoch 6: 100% 4/4 [00:01<00:00,  2.29it/s]\n",
            "12/12/2023 06:37:13 \n",
            "12/12/2023 06:37:13 [Epoch 6] [Loss: 4.257288] [Time: 1.751039]\n",
            "dev: 100% 1/1 [00:00<00:00,  2.03it/s]\n",
            "test: 100% 1/1 [00:01<00:00,  1.33s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.9306    0.4653    0.6204       144\n",
            "         sad     0.7105    0.8816    0.7869       245\n",
            "         neu     0.8438    0.7031    0.7670       384\n",
            "         ang     0.6154    0.8941    0.7290       170\n",
            "\n",
            "    accuracy                         0.7476       943\n",
            "   macro avg     0.7751    0.7360    0.7258       943\n",
            "weighted avg     0.7812    0.7476    0.7429       943\n",
            "\n",
            "12/12/2023 06:37:15 [Dev set] [f1 0.6329]\n",
            "12/12/2023 06:37:15 Save the best model.\n",
            "12/12/2023 06:37:15 [Test set] [f1 0.7429]\n",
            "train epoch 7: 100% 4/4 [00:02<00:00,  1.97it/s]\n",
            "12/12/2023 06:37:17 \n",
            "12/12/2023 06:37:17 [Epoch 7] [Loss: 4.102984] [Time: 2.029081]\n",
            "dev: 100% 1/1 [00:00<00:00,  2.74it/s]\n",
            "test: 100% 1/1 [00:00<00:00,  1.20it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8625    0.4792    0.6161       144\n",
            "         sad     0.6758    0.9020    0.7727       245\n",
            "         neu     0.8645    0.6979    0.7723       384\n",
            "         ang     0.6637    0.8824    0.7576       170\n",
            "\n",
            "    accuracy                         0.7508       943\n",
            "   macro avg     0.7666    0.7404    0.7297       943\n",
            "weighted avg     0.7790    0.7508    0.7459       943\n",
            "\n",
            "12/12/2023 06:37:19 [Dev set] [f1 0.7063]\n",
            "12/12/2023 06:37:19 Save the best model.\n",
            "12/12/2023 06:37:19 [Test set] [f1 0.7459]\n",
            "train epoch 8: 100% 4/4 [00:01<00:00,  2.27it/s]\n",
            "12/12/2023 06:37:21 \n",
            "12/12/2023 06:37:21 [Epoch 8] [Loss: 3.921849] [Time: 1.759399]\n",
            "dev: 100% 1/1 [00:00<00:00,  2.70it/s]\n",
            "test: 100% 1/1 [00:00<00:00,  1.19it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8778    0.5486    0.6752       144\n",
            "         sad     0.7023    0.8571    0.7721       245\n",
            "         neu     0.8359    0.7161    0.7714       384\n",
            "         ang     0.6667    0.8824    0.7595       170\n",
            "\n",
            "    accuracy                         0.7572       943\n",
            "   macro avg     0.7707    0.7511    0.7445       943\n",
            "weighted avg     0.7771    0.7572    0.7547       943\n",
            "\n",
            "12/12/2023 06:37:22 [Dev set] [f1 0.7071]\n",
            "12/12/2023 06:37:22 Save the best model.\n",
            "12/12/2023 06:37:22 [Test set] [f1 0.7547]\n",
            "train epoch 9: 100% 4/4 [00:01<00:00,  2.30it/s]\n",
            "12/12/2023 06:37:24 \n",
            "12/12/2023 06:37:24 [Epoch 9] [Loss: 3.966097] [Time: 1.739001]\n",
            "dev: 100% 1/1 [00:00<00:00,  2.64it/s]\n",
            "test: 100% 1/1 [00:00<00:00,  1.16it/s]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8667    0.5417    0.6667       144\n",
            "         sad     0.6987    0.8612    0.7715       245\n",
            "         neu     0.8373    0.7240    0.7765       384\n",
            "         ang     0.6895    0.8882    0.7763       170\n",
            "\n",
            "    accuracy                         0.7614       943\n",
            "   macro avg     0.7730    0.7538    0.7478       943\n",
            "weighted avg     0.7791    0.7614    0.7584       943\n",
            "\n",
            "12/12/2023 06:37:25 [Dev set] [f1 0.7172]\n",
            "12/12/2023 06:37:25 Save the best model.\n",
            "12/12/2023 06:37:25 [Test set] [f1 0.7584]\n",
            "train epoch 10: 100% 4/4 [00:01<00:00,  2.07it/s]\n",
            "12/12/2023 06:37:27 \n",
            "12/12/2023 06:37:27 [Epoch 10] [Loss: 3.649509] [Time: 1.928703]\n",
            "dev: 100% 1/1 [00:00<00:00,  2.04it/s]\n",
            "test: 100% 1/1 [00:01<00:00,  1.16s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8690    0.5069    0.6404       144\n",
            "         sad     0.6899    0.8898    0.7772       245\n",
            "         neu     0.8511    0.7292    0.7854       384\n",
            "         ang     0.7009    0.8824    0.7812       170\n",
            "\n",
            "    accuracy                         0.7646       943\n",
            "   macro avg     0.7777    0.7521    0.7460       943\n",
            "weighted avg     0.7849    0.7646    0.7604       943\n",
            "\n",
            "12/12/2023 06:37:29 [Dev set] [f1 0.7213]\n",
            "12/12/2023 06:37:29 Save the best model.\n",
            "12/12/2023 06:37:29 [Test set] [f1 0.7604]\n",
            "12/12/2023 06:37:29 \n",
            "12/12/2023 06:37:29 Best in epoch 10:\n",
            "dev: 100% 1/1 [00:00<00:00,  1.97it/s]\n",
            "12/12/2023 06:37:30 [Dev set] [f1 0.7213]\n",
            "test: 100% 1/1 [00:01<00:00,  1.04s/it]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hap     0.8690    0.5069    0.6404       144\n",
            "         sad     0.6899    0.8898    0.7772       245\n",
            "         neu     0.8511    0.7292    0.7854       384\n",
            "         ang     0.7009    0.8824    0.7812       170\n",
            "\n",
            "    accuracy                         0.7646       943\n",
            "   macro avg     0.7777    0.7521    0.7460       943\n",
            "weighted avg     0.7849    0.7646    0.7604       943\n",
            "\n",
            "12/12/2023 06:37:31 [Test set] f1 0.7603731563847743\n"
          ]
        }
      ]
    }
  ]
}